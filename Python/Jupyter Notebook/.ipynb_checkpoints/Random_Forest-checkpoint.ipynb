{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (19693, 476)\n",
      "Training Target Shape: (19693,)\n",
      "Testing Features Shape: (6565, 476)\n",
      "Testing Target Shape: (6565,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"data_clean.csv\")\n",
    "del df[\"Unnamed: 0\"]\n",
    "\n",
    "df['tax_class_at_time_of_sale'] = df['tax_class_at_time_of_sale'].astype('category')\n",
    "df['tax_class_at_present'] = df['tax_class_at_present'].astype('category')\n",
    "df['building_class category'] = df['building_class category'].astype('category')\n",
    "df['neighborhood'] = df['neighborhood'].astype('category')\n",
    "df['borough'] = df['borough'].astype('category')\n",
    "df['building_class_at_time_of_sale'] = df['building_class_at_time_of_sale'].astype('category')\n",
    "df['building_class_at_present'] = df['building_class_at_present'].astype('category')\n",
    "\n",
    "# One-hot encode the data using pandas get_dummies\n",
    "features = pd.get_dummies(df)\n",
    "\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(features['sale_price'])\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= features.drop('sale_price', axis = 1)\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "# Convert to numpy array\n",
    "features = np.array(features)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 1337)\n",
    "\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Target Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Target Shape:', test_labels.shape)\n",
    "\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 100 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 1337)\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2))\n",
    "\n",
    "predictions_all = np.array([tree.predict(test_features) for tree in rf.estimators_])\n",
    "print(predictions_all.shape) #(1000, 6565) 1000 rows: one for every Tree, 6565 columns, one for every target\n",
    "\n",
    "np.mean(predictions_all,axis=0)\n",
    "\n",
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];\n",
    "\n",
    "# Import matplotlib for plotting and use magic command for Jupyter Notebooks\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Set the style\n",
    "plt.style.use('fivethirtyeight')\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "# Make a bar chart\n",
    "plt.bar(x_values[:13], importances[:13], orientation = 'vertical')\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values[:13], feature_list[:13], rotation='vertical')\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variables'); plt.title('Variable Importance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.tree import export_graphviz\n",
    "#import pydot\n",
    "#from IPython.display import Image\n",
    "#from subprocess import call\n",
    "## Limit depth of tree to 3 levels\n",
    "#rf_small = RandomForestRegressor(n_estimators=10, max_depth = 3)\n",
    "#rf_small.fit(train_features, train_labels)\n",
    "## Extract the small tree\n",
    "#tree_small = rf_small.estimators_[5]\n",
    "## Export as dot file\n",
    "#export_graphviz(tree_small, out_file='smalltree.dot', \n",
    "                feature_names = feature_list,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png using system command (requires Graphviz)\n",
    "#from subprocess import call\n",
    "#call(['dot', '-Tpng', 'smalltree.dot', '-o', 'smalltree.png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "#from IPython.display import Image\n",
    "#Image(filename = 'smalltree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_clean.csv\")\n",
    "del df[\"Unnamed: 0\"]\n",
    "\n",
    "df = df[[\"gross_square_feet\",\"block\",\"land_square_feet\",\"lot\",\"age_of_building\",\"borough\",\"residential_units\",\"commercial_units\",\"total_units\",\"sale_price\"]]\n",
    "df['borough'] = df['borough'].astype('category')\n",
    "\n",
    "# One-hot encode the data using pandas get_dummies\n",
    "features = pd.get_dummies(df)\n",
    "\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(features['sale_price'])\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= features.drop('sale_price', axis = 1)\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "# Convert to numpy array\n",
    "features = np.array(features)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 1337)\n",
    "\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)\n",
    "\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 100 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 1337)\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels);\n",
    "\n",
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];\n",
    "\n",
    "# Import matplotlib for plotting and use magic command for Jupyter Notebooks\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Set the style\n",
    "plt.style.use('fivethirtyeight')\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "# Make a bar chart\n",
    "plt.bar(x_values[:13], importances[:13], orientation = 'vertical')\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values[:13], feature_list[:13], rotation='vertical')\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variables'); plt.title('Variable Importances');\n",
    "\n",
    "rf.get_params()\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "#rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "#rf_random = RandomizedSearchCV(estimator = rf,\n",
    "                               param_distributions = random_grid,\n",
    "                               n_iter = 100,\n",
    "                               cv = 3,\n",
    "                               verbose=2,\n",
    "                               random_state=1337,\n",
    "                               n_jobs = -1)\n",
    "# Fit the random search model\n",
    "#rf_random.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
